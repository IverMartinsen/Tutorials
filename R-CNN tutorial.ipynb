{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in training an R-CNN is to obtain image-level class examples which can be used for training a CNN. This CNN will later be used to extract features from region proposals. First step is to construct training data of individual objects of different size. These images are resized to a predefined size, before they are used to for training a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from utils import *\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "# next step: train a network on class example images\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(generate_background()); axes[0].axis('off')\n",
    "axes[1].imshow(generate_square()); axes[1].axis('off')\n",
    "axes[2].imshow(generate_circle()); axes[2].axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images are reshaped to a predefined size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (32, 32)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(tf.image.resize(generate_background(), size)); axes[0].axis('off')\n",
    "axes[1].imshow(tf.image.resize(generate_square(), size)); axes[1].axis('off')\n",
    "axes[2].imshow(tf.image.resize(generate_circle(), size)); axes[2].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a complete training set with n samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "image_set = np.zeros(shape=(3*n, ) + size + (3, ))\n",
    "image_labels = np.zeros(3*n).astype('int')\n",
    "\n",
    "for i in range(100):\n",
    "    image_set[i] = tf.image.resize(generate_background(), size)\n",
    "    image_labels[i] = 0\n",
    "    image_set[n + i] = tf.image.resize(generate_square(), size)\n",
    "    image_labels[n + i] = 1\n",
    "    image_set[2*n + i] = tf.image.resize(generate_circle(), size)\n",
    "    image_labels[2*n + i] = 2\n",
    "\n",
    "idx = np.random.choice(np.arange(3*n), 3*n)\n",
    "\n",
    "image_set = image_set[idx]\n",
    "image_labels = image_labels[idx]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(image_set[i]); ax.axis('off')\n",
    "    ax.set_title(f'Class {image_labels[i]}')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct a CNN and train for say 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# construct tf.Graph\n",
    "inputs = tf.keras.layers.Input(shape=size + (3, ))\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# define model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "\n",
    "model.fit(image_set, image_labels, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.zeros(shape=(3*n, ) + size + (3, ))\n",
    "test_labels = np.zeros(3*n).astype('int')\n",
    "\n",
    "for i in range(100):\n",
    "    test_images[i] = tf.image.resize(generate_background(), size)\n",
    "    test_labels[i] = 0\n",
    "    test_images[n + i] = tf.image.resize(generate_square(), size)\n",
    "    test_labels[n + i] = 1\n",
    "    test_images[2*n + i] = tf.image.resize(generate_circle(), size)\n",
    "    test_labels[2*n + i] = 2\n",
    "\n",
    "idx = np.random.choice(np.arange(3*n), 3*n)\n",
    "\n",
    "test_images = test_images[idx]\n",
    "test_labels = test_labels[idx]\n",
    "\n",
    "# print accuracy on test data\n",
    "print(f'Accuracy: {(np.sum(tf.argmax(model.predict(test_images), axis=1) == test_labels))/(3*n)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct an example image with circles and squares\n",
    "image = SampleImage((128, 128))\n",
    "image.add_circles(10)\n",
    "image.add_squares(10)\n",
    "\n",
    "# display example image along with proposed regions\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "ax1.imshow(image.pixels, cmap='gray')\n",
    "ax2.imshow(mark_boundaries(image.pixels, felzenszwalb(image.pixels, scale=1)))\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a neural network that is able to adequately discriminate between our classes. Next we need to\n",
    "1 create an image with several objects in it with known bounding boxes\n",
    "2 extract region proposals from an image\n",
    "3 compare each region proposal with the ground truth. If IOU > 0.5 the region proposal is positive for that class. If IoU is < 0.3 for all ground truth bounding boxes, the region is positive for background.\n",
    "4 Extract features from the proposals using the previously trained network, and use the feature vectors as input to an SVM for each class.\n",
    "5 Bounding box regression and non-max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: create tight bounding boxes around region proposals\n",
    "\n",
    "# tile bounding box proposals\n",
    "dense_proposals = felzenszwalb(image.pixels)\n",
    "num_proposals = len(np.unique(dense_proposals)) - 1\n",
    "proposals = np.zeros(shape=image.shape + (num_proposals, ))\n",
    "\n",
    "for i in range(num_proposals):\n",
    "    proposals[:, :, i] = dense_proposals == i + 1\n",
    "\n",
    "proposals.shape\n",
    "# match tiled array with constant array of same size\n",
    "# for all proposals, compute IOU to all true class regions and label them to class if IOU is over 50\n",
    "\n",
    "#test = np.ones(shape=(3, 4, 5))\n",
    "#print(test == np.ones_like(test)*0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc9d4bc4729ab5a16e3b97a2af446a0f2be641d87d4d6568ca073f9335f1f24"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
